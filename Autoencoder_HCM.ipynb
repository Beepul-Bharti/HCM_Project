{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for HCM Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from scipy import ndimage\n",
    "from skimage.transform import rescale\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "import PIL\n",
    "print('Pillow Version:', PIL.__version__)\n",
    "import glob\n",
    "from matplotlib import image\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv3D\n",
    "from tensorflow.keras.layers import MaxPooling3D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load training images into directory\n",
    "trainingpath = '/home/beepul/HCM-Project/ModifiedROI_4ChamberCine/Training'\n",
    "loaded_images = list()\n",
    "TopDirectory = listdir(trainingpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in training table\n",
    "patientlist = []\n",
    "training_df = pd.read_excel('/home/beepul/HCM-Project/HCM_Methods_Data/OrganizedData/Training.xls')\n",
    "for patients in training_df['PatientNumber']:\n",
    "    patientlist.append(str(patients))\n",
    "training_df['PatientNumber'] = patientlist\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frame to store relevant properties of each patient/image\n",
    "num_patients = len(TopDirectory)\n",
    "df = pd.DataFrame(columns = ['PatientNumber','Image','X_res','Y_res','X_length','Y_length','Outcome'])\n",
    "df.PatientNumber = TopDirectory\n",
    "\n",
    "# Load in each image and store in data frame\n",
    "for i in range(num_patients):\n",
    "    patient = df.PatientNumber[i]\n",
    "    properties = training_df[training_df['PatientNumber'] == patient]\n",
    "    index = properties.index[0]\n",
    "    df.Outcome[i] = properties.Outcome[index]\n",
    "    df.X_length[i], df.Y_length[i] = properties.X_Length[index], properties.Y_Length[index]\n",
    "    df.X_res[i], df.Y_res[i] = properties.Xres[index], properties.Yres[index]\n",
    "    imagepath = trainingpath + '/' + patient\n",
    "    image_dir = listdir(imagepath)\n",
    "    x_dim, y_dim = plt.imread(imagepath + '/' + str(1) + '.png').shape\n",
    "    num_frames = len(image_dir)\n",
    "    img_data = np.zeros((x_dim,y_dim,num_frames))\n",
    "    for k in range(num_frames):\n",
    "        framepath = imagepath + '/' + str(k+1) + '.png'\n",
    "        img_data[:,:,(k)] = plt.imread(framepath)\n",
    "    df.Image[i] = img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load random montage to ensure the images loaded in correctly\n",
    "volume = df.Image[3]\n",
    "plt.figure(figsize=(20,10))\n",
    "columns = 6\n",
    "for i in range(volume.shape[2]):\n",
    "    image = volume[:,:,i]\n",
    "    plt.subplot(5, columns, i + 1)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Padding volumes to ensure sizes of images are correctly proportional to each other\n",
    "\n",
    "# Find max_x and max_y\n",
    "max_x_ind = pd.to_numeric(df.X_length).idxmax()\n",
    "max_y_ind = pd.to_numeric(df.Y_length).idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine largest image within the training set\n",
    "max_volume = df.iloc[max_x_ind]\n",
    "max_y_length = max_volume['Y_length']\n",
    "max_y_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to properly pad images\n",
    "# Input: Patient, desired x and y resolution\n",
    "# Output: Resized and padded image\n",
    "def pad(patient,d_x_res,d_y_res):\n",
    "    image = patient.Image\n",
    "    num_frames = image.shape[2]\n",
    "    Y_length = patient.Y_length\n",
    "    p = d_y_res*(Y_length/max_y_length)\n",
    "    c_y_res = patient.Y_res\n",
    "    scale = p/c_y_res\n",
    "    resized_image = np.zeros((d_x_res,d_y_res,num_frames))\n",
    "    for j in range(num_frames):\n",
    "        frame = image[:,:,j]\n",
    "        resized_frame = rescale(frame,scale)\n",
    "        padded_frame = np.pad(resized_frame,((0,256-resized_frame.shape[0]),(0,256-resized_frame.shape[1])),'constant')\n",
    "        resized_image[:,:,j] = padded_frame\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load random montage to ensure the padding works correctly\n",
    "patient = df.iloc[3]\n",
    "resized_image = pad(patient,256,256)\n",
    "volume = resized_image\n",
    "plt.figure(figsize=(20,10))\n",
    "columns = 6\n",
    "for i in range(volume.shape[2]):\n",
    "    image = volume[:,:,i]\n",
    "    plt.subplot(5, columns, i + 1)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take images with 50 frames and reduce to 30 frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = np.empty(df.shape[0])\n",
    "training_labels = np.empty(df.shape[0])\n",
    "for i in range(df.shape[0]):\n",
    "    resized_image = pad(df.iloc[i],256,256)\n",
    "    training_images[i] = resized_image\n",
    "    training_labels[i] = df.Outcome[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently Assuming that the input images are 150x150 with 30 frames\n",
    "# Channel = 1 because they are grayscale\n",
    "# This architecure is DEFINITELY subject to change\n",
    "\n",
    "# Input Data\n",
    "input_data = layers.Input([150,150,30,1])\n",
    "\n",
    "# Conv 1.1\n",
    "encoder = Conv3D(4,(3,3,3), strides=(1,1,1), activation=\"relu\",padding = \"same\")(input_data)\n",
    "encoder = BatchNormalization(center=True, scale=True)(encoder)\n",
    "encoder = Conv3D(4,(3,3,3), strides=(1,1,1), activation=\"relu\",padding = \"same\")(encoder)\n",
    "encoder = BatchNormalization(center=True, scale=True)(encoder)\n",
    "encoder = MaxPooling3D(pool_size = (2,2,2), strides=(2,2,2))(encoder)\n",
    "\n",
    "# Conv 2.1\n",
    "encoder = Conv3D(8,(3,3,3), strides=(1,1,1), activation=\"relu\",padding = \"same\")(encoder)\n",
    "encoder = BatchNormalization(center=True, scale=True)(encoder)\n",
    "encoder = Conv3D(8,(3,3,3), strides=(1,1,1), activation=\"relu\",padding = \"same\")(encoder)\n",
    "encoder = BatchNormalization(center=True, scale=True)(encoder)\n",
    "encoder = MaxPooling3D(pool_size = (3,3,3), strides=(3,3,3))(encoder)\n",
    "\n",
    "# Conv 3.1\n",
    "encoder = Conv3D(16,(3,3,3), strides=(1,1,1), activation=\"relu\",padding = \"same\")(encoder)\n",
    "encoder = BatchNormalization(center=True, scale=True)(encoder)\n",
    "encoder = Conv3D(16,(3,3,3), strides=(1,1,1), activation=\"relu\",padding = \"same\")(encoder)\n",
    "encoder = BatchNormalization(center=True, scale=True)(encoder)\n",
    "encoder = MaxPooling3D(pool_size = (3,3,3), strides=(5,5,5), padding = \"same\")(encoder)\n",
    "\n",
    "# Size of data after convolutional layers\n",
    "volumesize = tf.keras.backend.int_shape(encoder)\n",
    "\n",
    "# Fully Connected\n",
    "# 1st layer\n",
    "encoder = Flatten()(encoder)\n",
    "dense1_size = tf.keras.backend.int_shape(encoder)\n",
    "\n",
    "# 2nd layer\n",
    "encoder = layers.Dense(100)(encoder)\n",
    "\n",
    "# Classifying layer\n",
    "encoder_cnn = layers.Dense(2)(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 150, 150, 30, 1)] 0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 150, 150, 30, 4)   112       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 150, 150, 30, 4)   16        \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 150, 150, 30, 4)   436       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 150, 150, 30, 4)   16        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 75, 75, 15, 4)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 75, 75, 15, 8)     872       \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 75, 75, 15, 8)     32        \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 75, 75, 15, 8)     1736      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 75, 75, 15, 8)     32        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 25, 25, 5, 8)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 25, 25, 5, 16)     3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 25, 25, 5, 16)     64        \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 25, 25, 5, 16)     6928      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 25, 25, 5, 16)     64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 5, 5, 1, 16)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               40100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 54,082\n",
      "Trainable params: 53,970\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary of the encoder \n",
    "encoder_model = tf.keras.Model(input_data, encoder_cnn, name=\"encoder\")\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Decoder\n",
    "decoder = layers.Dense(dense1_size[1])(encoder)\n",
    "decoder = layers.Reshape(volumesize[1:])(decoder)\n",
    "\n",
    "# Deconv 1.1\n",
    "decoder = Conv3D(16,(3,3,3), strides=(1,1,1), activation=\"relu\",padding = \"same\")(decoder)\n",
    "decoder = layers.BatchNormalization(center=True, scale=True)(decoder)\n",
    "decoder = Conv3D(16,(3,3,3), strides=(1,1,1), activation=\"relu\",padding = \"same\")(decoder)\n",
    "decoder = layers.BatchNormalization(center=True, scale=True)(decoder)\n",
    "decoder = layers.UpSampling3D([5,5,5])(decoder)\n",
    "\n",
    "# Deconv 2.1\n",
    "decoder = Conv3D(8,(3,3,3), strides=(1,1,1), activation=\"relu\",padding = \"same\")(decoder)\n",
    "decoder = layers.BatchNormalization(center=True, scale=True)(decoder)\n",
    "decoder = Conv3D(8,(3,3,3), strides=(1,1,1), activation=\"relu\",padding = \"same\")(decoder)\n",
    "decoder = layers.BatchNormalization(center=True, scale=True)(decoder)\n",
    "decoder = layers.UpSampling3D([3,3,3])(decoder)\n",
    "\n",
    "# Deconv 2.1\n",
    "decoder = Conv3D(4,(3,3,3), strides=(1,1,1), activation=\"relu\",padding = \"same\")(decoder)\n",
    "decoder = layers.BatchNormalization(center=True, scale=True)(decoder)\n",
    "decoder = Conv3D(4,(3,3,3), strides=(1,1,1), activation=\"relu\",padding = \"same\")(decoder)\n",
    "decoder = layers.BatchNormalization(center=True, scale=True)(decoder)\n",
    "decoder = layers.UpSampling3D([2,2,2])(decoder)\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_48 (InputLayer)        [(None, 150, 150, 30, 1)] 0         \n",
      "_________________________________________________________________\n",
      "conv3d_216 (Conv3D)          (None, 150, 150, 30, 4)   112       \n",
      "_________________________________________________________________\n",
      "batch_normalization_228 (Bat (None, 150, 150, 30, 4)   16        \n",
      "_________________________________________________________________\n",
      "conv3d_217 (Conv3D)          (None, 150, 150, 30, 4)   436       \n",
      "_________________________________________________________________\n",
      "batch_normalization_229 (Bat (None, 150, 150, 30, 4)   16        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_104 (MaxPoolin (None, 75, 75, 15, 4)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_218 (Conv3D)          (None, 75, 75, 15, 8)     872       \n",
      "_________________________________________________________________\n",
      "batch_normalization_230 (Bat (None, 75, 75, 15, 8)     32        \n",
      "_________________________________________________________________\n",
      "conv3d_219 (Conv3D)          (None, 75, 75, 15, 8)     1736      \n",
      "_________________________________________________________________\n",
      "batch_normalization_231 (Bat (None, 75, 75, 15, 8)     32        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_105 (MaxPoolin (None, 25, 25, 5, 8)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_220 (Conv3D)          (None, 25, 25, 5, 16)     3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_232 (Bat (None, 25, 25, 5, 16)     64        \n",
      "_________________________________________________________________\n",
      "conv3d_221 (Conv3D)          (None, 25, 25, 5, 16)     6928      \n",
      "_________________________________________________________________\n",
      "batch_normalization_233 (Bat (None, 25, 25, 5, 16)     64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_106 (MaxPoolin (None, 5, 5, 1, 16)       0         \n",
      "_________________________________________________________________\n",
      "flatten_42 (Flatten)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 350)               140350    \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 400)               140400    \n",
      "_________________________________________________________________\n",
      "reshape_26 (Reshape)         (None, 5, 5, 1, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_226 (Conv3D)          (None, 5, 5, 1, 16)       6928      \n",
      "_________________________________________________________________\n",
      "batch_normalization_238 (Bat (None, 5, 5, 1, 16)       64        \n",
      "_________________________________________________________________\n",
      "conv3d_227 (Conv3D)          (None, 5, 5, 1, 16)       6928      \n",
      "_________________________________________________________________\n",
      "batch_normalization_239 (Bat (None, 5, 5, 1, 16)       64        \n",
      "_________________________________________________________________\n",
      "up_sampling3d_6 (UpSampling3 (None, 25, 25, 5, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_228 (Conv3D)          (None, 25, 25, 5, 8)      3464      \n",
      "_________________________________________________________________\n",
      "batch_normalization_240 (Bat (None, 25, 25, 5, 8)      32        \n",
      "_________________________________________________________________\n",
      "conv3d_229 (Conv3D)          (None, 25, 25, 5, 8)      1736      \n",
      "_________________________________________________________________\n",
      "batch_normalization_241 (Bat (None, 25, 25, 5, 8)      32        \n",
      "_________________________________________________________________\n",
      "up_sampling3d_7 (UpSampling3 (None, 75, 75, 15, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_230 (Conv3D)          (None, 75, 75, 15, 4)     868       \n",
      "_________________________________________________________________\n",
      "batch_normalization_242 (Bat (None, 75, 75, 15, 4)     16        \n",
      "_________________________________________________________________\n",
      "conv3d_231 (Conv3D)          (None, 75, 75, 15, 4)     436       \n",
      "_________________________________________________________________\n",
      "batch_normalization_243 (Bat (None, 75, 75, 15, 4)     16        \n",
      "_________________________________________________________________\n",
      "up_sampling3d_8 (UpSampling3 (None, 150, 150, 30, 4)   0         \n",
      "=================================================================\n",
      "Total params: 315,114\n",
      "Trainable params: 314,890\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Full Autoencoder Summary\n",
    "\n",
    "autoencoder_model = tf.keras.Model(input_data, decoder, name=\"autoencoder\")\n",
    "autoencoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = tf.keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(50)(x)\n",
    "# at this point the representation is 50 dimensions\n",
    "\n",
    "x = layers.Dense(128)(x)\n",
    "x = layers.Reshape([4,4,8])(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = layers.UpSampling2D((2, 2))(x)\n",
    "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_40 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 14, 14, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 7, 7, 8)           584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 128)               6528      \n",
      "_________________________________________________________________\n",
      "reshape_22 (Reshape)         (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 4, 4, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 8, 8, 8)           584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2 (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 17,363\n",
      "Trainable params: 17,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "example = tf.keras.Model(input_img, decoded, name=\"autoencoder\")\n",
    "example.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
